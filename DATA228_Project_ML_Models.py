# -*- coding: utf-8 -*-
"""Data228_Project_ml_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XpIFsvSgU5R2Nb-rWFCIS79iyVGv_Gx1
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.preprocessing import LabelEncoder
from imblearn.under_sampling import RandomUnderSampler

from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.classification import RandomForestClassifier, GBTClassifier
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.feature import StringIndexer
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.classification import RandomForestClassificationModel

np.random.seed(42)

pip install pyspark

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

"""Load feature data"""

dataset_path = '/content/drive/Shared drives/DATA 228/Group Project/'

'''load feature data'''

feature_file_paths = [
    dataset_path+'dataset/46013h2014.txt', dataset_path+'dataset/46013h2015.txt', dataset_path+'dataset/46013h2016.txt', dataset_path+'dataset/46013h2017.txt', dataset_path+'dataset/46013h2018.txt', dataset_path+'dataset/46013h2019.txt', dataset_path+'dataset/46013h2021.txt', dataset_path+'dataset/46013h2022.txt',
    dataset_path+'dataset/46026h2014.txt', dataset_path+'dataset/46026h2015.txt', dataset_path+'dataset/46026h2016.txt', dataset_path+'dataset/46026h2017.txt', dataset_path+'dataset/46026h2018.txt', dataset_path+'dataset/46026h2019.txt', dataset_path+'dataset/46026h2020.txt', dataset_path+'dataset/46026h2021.txt', dataset_path+'dataset/46026h2022.txt',
    dataset_path+'dataset/46237h2014.txt', dataset_path+'dataset/46237h2015.txt', dataset_path+'dataset/46237h2016.txt', dataset_path+'dataset/46237h2017.txt', dataset_path+'dataset/46237h2018.txt', dataset_path+'dataset/46237h2019.txt', dataset_path+'dataset/46237h2020.txt', dataset_path+'dataset/46237h2021.txt', dataset_path+'dataset/46237h2022.txt',
    dataset_path+'dataset/ftpc1h2014.txt', dataset_path+'dataset/ftpc1h2015.txt', dataset_path+'dataset/ftpc1h2016.txt', dataset_path+'dataset/ftpc1h2017.txt', dataset_path+'dataset/ftpc1h2018.txt', dataset_path+'dataset/ftpc1h2019.txt', dataset_path+'dataset/ftpc1h2020.txt', dataset_path+'dataset/ftpc1h2021.txt', dataset_path+'dataset/ftpc1h2022.txt',
    dataset_path+'dataset/pxoc1h2014.txt', dataset_path+'dataset/pxoc1h2015.txt', dataset_path+'dataset/pxoc1h2016.txt', dataset_path+'dataset/pxoc1h2017.txt', dataset_path+'dataset/pxoc1h2018.txt', dataset_path+'dataset/pxoc1h2019.txt', dataset_path+'dataset/pxoc1h2020.txt', dataset_path+'dataset/pxoc1h2021.txt', dataset_path+'dataset/pxoc1h2022.txt',
    dataset_path+'dataset/pxsc1h2014.txt', dataset_path+'dataset/pxsc1h2015.txt', dataset_path+'dataset/pxsc1h2016.txt', dataset_path+'dataset/pxsc1h2017.txt', dataset_path+'dataset/pxsc1h2018.txt', dataset_path+'dataset/pxsc1h2019.txt', dataset_path+'dataset/pxsc1h2020.txt', dataset_path+'dataset/pxsc1h2021.txt', dataset_path+'dataset/pxsc1h2022.txt',
    dataset_path+'dataset/tibc1h2015.txt', dataset_path+'dataset/tibc1h2016.txt', dataset_path+'dataset/tibc1h2017.txt', dataset_path+'dataset/tibc1h2018.txt', dataset_path+'dataset/tibc1h2019.txt', dataset_path+'dataset/tibc1h2020.txt', dataset_path+'dataset/tibc1h2021.txt', dataset_path+'dataset/tibc1h2022.txt'
]


# Initialize an empty DataFrame to store the combined feature data
all_feature_data = pd.DataFrame()

for feature_file_path in feature_file_paths:
    feature_data = pd.read_csv(feature_file_path, delim_whitespace=True, skiprows=[1])
    feature_data['timestamp'] = pd.to_datetime(feature_data[['#YY', 'MM', 'DD', 'hh', 'mm']].astype(str).agg(' '.join, axis=1), format='%Y %m %d %H %M')
    feature_data['year'] = feature_data['timestamp'].dt.year
    feature_data['month'] = feature_data['timestamp'].dt.month
    feature_data['day'] = feature_data['timestamp'].dt.day
    feature_data['hour'] = feature_data['timestamp'].dt.hour
    feature_data['minute'] = feature_data['timestamp'].dt.minute
    all_feature_data = pd.concat([all_feature_data, feature_data], axis=0, ignore_index=True)


print(f'total count of feature data: {all_feature_data.shape[0]}')



# Define the missing value patterns
missing_patterns = [99.00, 999, 999.0, 99.0]

# Loop through each column and replace each pattern with NaN
for column in all_feature_data.columns:
    for pattern in missing_patterns:
        all_feature_data[column] = all_feature_data[column].replace(to_replace=pattern, value=np.nan, regex=True)

missing_data = all_feature_data.isnull().sum()
# Display missing data count for each column
print('missing data count in raw data:')
print(missing_data)

# Setting threshold for excessive missing values (e.g., 60%)
threshold = 0.6 * len(all_feature_data)

# Drop columns with missing values greater than the threshold
all_feature_data.dropna(axis=1, thresh=threshold, inplace=True)

# Drop rows with any missing values
all_feature_data.dropna(axis=0, inplace=True)

"""Load target file"""

'''Load target file'''
target_file_path = dataset_path+'dataset/storm_data_search_results.csv'
target_data = pd.read_csv(target_file_path, sep=',')

print(target_data.head(2).to_string())

# Keep only specific columns
selected_columns = ['BEGIN_DATE', 'BEGIN_TIME', 'EVENT_TYPE']
target_data = target_data[selected_columns]

# convert the TIME columns to hourly timestamp
target_data['BEGIN_TIME'] = (target_data['BEGIN_TIME'].floordiv(100))
target_data['BEGIN_TIME'] = target_data['BEGIN_TIME'].astype(str) + '00'

# Convert timestamp columns to a single datetime column
target_data['timestamp'] = pd.to_datetime(target_data[['BEGIN_DATE', 'BEGIN_TIME']].astype(str).agg(' '.join, axis=1), format='%m/%d/%Y %H%M')

'''Merge feature and target data based on the timestamp'''
# Merge feature and target data based on the timestamp as event data
all_event_data = pd.merge(all_feature_data, target_data, how='right', on='timestamp')

# Merge feature and target data based on the timestamp as other data
all_other_data = pd.merge(all_feature_data, target_data, how='left', on='timestamp')
all_other_data['EVENT_TYPE'].fillna('no', inplace=True)

# concatenate two partial data into a whole dataset
all_data = pd.concat([all_event_data, all_other_data])

# drop some unuseful columns
all_data = all_data.drop(['timestamp','BEGIN_DATE', 'BEGIN_TIME', '#YY', 'MM', 'DD', 'hh', 'mm', 'year', 'month', 'day', 'hour', 'minute'], axis=1)
# Drop rows with any missing values
all_data.dropna(axis=0, inplace=True)
all_data.loc[all_data["EVENT_TYPE"] != "no", "EVENT_TYPE"] = 'yes'

print('missing data count in prepared data:')
missing_data_prepared = all_data.isnull().sum()
print(missing_data_prepared)

print(f'total count of prepared data: {len(all_data)}')

all_data

"""Identify features and target variable"""

# Identify features and target variable
X = all_data.drop(['EVENT_TYPE'], axis=1)
y = all_data['EVENT_TYPE']

yes_count = all_data['EVENT_TYPE'].value_counts().get('yes', 0)
no_count = all_data['EVENT_TYPE'].value_counts().get('no', 0)
print(yes_count)
print(no_count)

"""Split training and test dataset"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
# Combine X_train and y_train into a single DataFrame for undersampling
train_data = pd.concat([X_train, y_train], axis=1)

# Identify the minority class label
minority_class_label = train_data['EVENT_TYPE'].value_counts().idxmin()

# Apply random undersampling
undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)
X_resampled, y_resampled = undersampler.fit_resample(train_data.drop('EVENT_TYPE', axis=1), train_data['EVENT_TYPE'])
print(y_resampled.value_counts())

print(type(X_resampled))

df_train = pd.concat([X_resampled, y_resampled], axis = 1)
df_test = pd.concat([X_test, y_test], axis = 1)

# Building the SparkSession and name
# it :'pandas to spark'
spark = SparkSession.builder.appName("ML_App").getOrCreate()

# create DataFrame
df_train_spark = spark.createDataFrame(df_train)

df_test_spark = spark.createDataFrame(df_test)

# Create a feature vector by combining all the features
assembler = VectorAssembler(inputCols=["WDIR", "WSPD", "GST", "PRES", "ATMP"], outputCol="features")

# Transform the data to create the feature vector
train_data = assembler.transform(df_train_spark)
test_data = assembler.transform(df_test_spark)

label_stringIdx = StringIndexer(inputCol = 'EVENT_TYPE', outputCol = 'labelIndex')
train_data = label_stringIdx.fit(train_data).transform(train_data)
test_data = label_stringIdx.fit(test_data).transform(test_data)
train_data.show()

"""Random Forest Classifier"""

from pyspark.ml.classification import RandomForestClassifier

rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'labelIndex', numTrees=40, maxDepth=3)
rf_model = rf.fit(train_data)
rf_predictions = rf_model.transform(test_data)
# rf_predictions.select('labelIndex', 'rawPrediction', 'prediction', 'probability').show(25)

from pyspark.ml.evaluation import MulticlassClassificationEvaluator

rf_evaluator = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction")
accuracy = rf_evaluator.evaluate(rf_predictions)
print(f'Accuracy = {accuracy:.4f}')
print(f'Test Error = {(1.0 - accuracy):.4f}')

# Evaluate recall
recall_evaluator = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="weightedRecall")
recall = recall_evaluator.evaluate(rf_predictions)
print(f'Recall = {recall:.4f}')

# Evaluate precision
precision_evaluator = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="weightedPrecision")
precision = precision_evaluator.evaluate(rf_predictions)
print(f'Precision = {precision:.4f}')

# Evaluate F1 score
f1_evaluator = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="f1")
f1 = f1_evaluator.evaluate(rf_predictions)
print(f'F1 Score = {f1:.4f}')

# Evaluate area under ROC curve
auc_evaluator = BinaryClassificationEvaluator(labelCol="labelIndex", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
auc = auc_evaluator.evaluate(rf_predictions)
print(f'AUC = {auc:.4f}')

"""Gradient Boosting Classifier"""

from pyspark.ml.classification import GBTClassifier

gb = GBTClassifier(featuresCol = 'features', labelCol = 'labelIndex', maxIter=50)
gb_model = gb.fit(train_data)
gb_predictions = gb_model.transform(test_data)

gb_evaluator = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction")
accuracy = gb_evaluator.evaluate(gb_predictions)
print(f'Accuracy = {accuracy:.4f}')
print(f'Test Error = {(1.0 - accuracy):.4f}')

# Evaluate recall
recall_evaluator_gb = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="weightedRecall")
recall_gb = recall_evaluator_gb.evaluate(gb_predictions)
print(f'Recall = {recall_gb:.4f}')

# Evaluate precision
precision_evaluator_gb = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="weightedPrecision")
precision_gb = precision_evaluator_gb.evaluate(gb_predictions)
print(f'Precision = {precision_gb:.4f}')

# Evaluate F1 score
f1_evaluator_gb = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="f1")
f1_gb = f1_evaluator_gb.evaluate(gb_predictions)
print(f'F1 Score = {f1_gb:.4f}')

# Evaluate area under ROC curve
auc_evaluator_gb = BinaryClassificationEvaluator(labelCol="labelIndex", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
auc_gb = auc_evaluator_gb.evaluate(gb_predictions)
print(f'AUC = {auc_gb:.4f}')

"""XGBoost"""

from xgboost.spark import SparkXGBClassifier

xgb = SparkXGBClassifier(label_col="labelIndex", missing=0.0)
xgb_model = xgb.fit(train_data)
xgb_predictions = xgb_model.transform(test_data)

xgb_evaluator = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction")
accuracy = xgb_evaluator.evaluate(xgb_predictions)
print(f'Accuracy = {accuracy:.4f}')
print(f'Test Error = {(1.0 - accuracy):.4f}')

# Evaluate recall
recall_evaluator_xgb = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="weightedRecall")
recall_xgb = recall_evaluator_xgb.evaluate(xgb_predictions)
print(f'Recall = {recall_xgb:.4f}')

# Evaluate F1 score
f1_evaluator_xgb = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="f1")
f1_xgb = f1_evaluator_xgb.evaluate(xgb_predictions)
print(f'F1 Score = {f1_xgb:.4f}')

# Evaluate precision
precision_evaluator_xgb = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="weightedPrecision")
precision_xgb = precision_evaluator_xgb.evaluate(xgb_predictions)
print(f'Precision = {precision_xgb:.4f}')

# Evaluate area under ROC curve
auc_evaluator_xgb = BinaryClassificationEvaluator(labelCol="labelIndex", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
auc_xgb = auc_evaluator_xgb.evaluate(xgb_predictions)
print(f'AUC = {auc_xgb:.4f}')

